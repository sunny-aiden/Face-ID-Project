{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc70fc33",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bf9bd",
   "metadata": {},
   "source": [
    "Traditional ML — Grid / Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e38febd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (7836, 1280) (7836,)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "FEAT = Path(r\"C:\\Users\\상선\\Face-ID-Project\\features\")          #  ←  no “..” here\n",
    "X_train = np.load(FEAT / \"X_train.npy\")\n",
    "y_train = np.load(FEAT / \"y_train.npy\")\n",
    "X_val   = np.load(FEAT / \"X_val.npy\")\n",
    "y_val   = np.load(FEAT / \"y_val.npy\")\n",
    "\n",
    "print(\"shapes:\", X_train.shape, y_train.shape)   # should print e.g. (7836, 1280) (7836,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0607ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=1e-06 eta0=1e-03 lr=optimal    → val 0.393  (229.7s)\n",
      "alpha=3e-06 eta0=3e-03 lr=optimal    → val 0.405  (336.9s)\n",
      "alpha=1e-05 eta0=1e-03 lr=adaptive   → val 0.399  (621.4s)\n",
      "alpha=3e-05 eta0=3e-03 lr=adaptive   → val 0.309  (689.9s)\n",
      "alpha=1e-04 eta0=1e-02 lr=adaptive   → val 0.248  (909.9s)\n",
      "alpha=1e-05 eta0=1e-02 lr=invscaling → val 0.226  (204.0s)\n",
      "alpha=3e-05 eta0=3e-03 lr=invscaling → val 0.226  (432.2s)\n",
      "alpha=1e-04 eta0=1e-03 lr=optimal    → val 0.387  (508.7s)\n",
      "Best config: (3e-06, 0.003, 'optimal'), val‑acc: 0.405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_best.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression – GridSearch\n",
    "# Fast manual search for linear SVM via SGD (hinge)\n",
    "import time, numpy as np, joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# (Optional) use float32 to reduce memory/compute\n",
    "X_train32 = X_train.astype(np.float32, copy=False)\n",
    "X_val32   = X_val.astype(np.float32, copy=False)\n",
    "\n",
    "def build_sgd(alpha, eta0, lr):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),  # embeddings are dense; centering helps\n",
    "        (\"clf\", SGDClassifier(loss=\"hinge\",\n",
    "                              alpha=alpha, learning_rate=lr, eta0=eta0,\n",
    "                              max_iter=2000, tol=1e-3, random_state=42))\n",
    "    ])\n",
    "\n",
    "candidates = [\n",
    "    # (alpha, eta0, lr)\n",
    "    (1e-6, 1e-3, \"optimal\"),\n",
    "    (3e-6, 3e-3, \"optimal\"),\n",
    "    (1e-5, 1e-3, \"adaptive\"),\n",
    "    (3e-5, 3e-3, \"adaptive\"),\n",
    "    (1e-4, 1e-2, \"adaptive\"),\n",
    "    (1e-5, 1e-2, \"invscaling\"),\n",
    "    (3e-5, 3e-3, \"invscaling\"),\n",
    "    (1e-4, 1e-3, \"optimal\"),\n",
    "]\n",
    "\n",
    "best_acc, best_model, best_cfg = 0.0, None, None\n",
    "for a, e, lr in candidates:\n",
    "    t0 = time.time()\n",
    "    model = build_sgd(a, e, lr)\n",
    "    model.fit(X_train32, y_train)\n",
    "    acc = accuracy_score(y_val, model.predict(X_val32))\n",
    "    print(f\"alpha={a:.0e} eta0={e:.0e} lr={lr:10s} → val {acc:.3f}  ({time.time()-t0:.1f}s)\")\n",
    "    if acc > best_acc:\n",
    "        best_acc, best_model, best_cfg = acc, model, (a,e,lr)\n",
    "\n",
    "print(f\"Best config: {best_cfg}, val‑acc: {best_acc:.3f}\")\n",
    "joblib.dump(best_model, \"svm_best.pkl\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d8845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\상선\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM – RandomizedSearch\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition   import IncrementalPCA\n",
    "from sklearn.linear_model    import SGDClassifier\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.metrics         import accuracy_score\n",
    "import numpy as np, time, joblib\n",
    "\n",
    "# \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xtr = scaler.transform(X_train).astype(np.float32, copy=False)\n",
    "Xv  = scaler.transform(X_val).astype(np.float32, copy=False)\n",
    "\n",
    "pca    = IncrementalPCA(n_components=256, batch_size=512).fit(Xtr)\n",
    "Xtr256 = pca.transform(Xtr)\n",
    "Xv256  = pca.transform(Xv)\n",
    "\n",
    "# 2)\n",
    "candidates = [\n",
    "    (1e-5, 1e-3, \"adaptive\"),\n",
    "    (3e-5, 3e-3, \"optimal\"),\n",
    "    (1e-4, 1e-2, \"adaptive\"),\n",
    "    (1e-4, 1e-3, \"invscaling\"),\n",
    "    (3e-5, 1e-2, \"adaptive\"),\n",
    "]\n",
    "\n",
    "best_acc, best_clf, best_cfg = 0, None, None\n",
    "for a,e,lr in candidates:\n",
    "    t0 = time.time()\n",
    "    clf = Pipeline([\n",
    "        (\"clf\", SGDClassifier(loss=\"hinge\",\n",
    "                              alpha=a, learning_rate=lr, eta0=e,\n",
    "                              max_iter=500, tol=1e-3, random_state=42))\n",
    "    ])\n",
    "    clf.fit(Xtr256, y_train)              \n",
    "    acc = accuracy_score(y_val, clf.predict(Xv256))\n",
    "    print(f\"{(a,e,lr)} → val {acc:.3f} ({time.time()-t0:.1f}s)\")\n",
    "    if acc > best_acc:\n",
    "        best_acc, best_clf, best_cfg = acc, clf, (a,e,lr)\n",
    "\n",
    "print(\"Best:\", best_cfg, \"val‑acc\", best_acc)\n",
    "# 3)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(pca,    \"pca256.pkl\")\n",
    "joblib.dump(best_clf, \"svm_best.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K‑NN – GridSearch\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),   # cosine dist doesn’t need centering\n",
    "    (\"clf\", KNeighborsClassifier(metric=\"cosine\"))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__n_neighbors\": [3, 5, 7, 9],\n",
    "    \"clf__weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(knn_pipe, param_grid, cv=3, scoring=\"accuracy\",\n",
    "                      n_jobs=-1, verbose=1)\n",
    "gs_knn.fit(X_train, y_train)\n",
    "print(\"Best KNN:\", gs_knn.best_params_, \"→\", gs_knn.best_score_)\n",
    "joblib.dump(gs_knn.best_estimator_, \"knn_best.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca709dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(gs_log.cv_results_).to_csv(\"logreg_grid_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbde9a",
   "metadata": {},
   "source": [
    "CNN — Optuna Bayesian Search (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47f619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective\n",
    "import optuna, torch, torch.nn as nn, copy, time\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "def objective(trial):\n",
    "    # hyper‑params to explore\n",
    "    lr         = trial.suggest_loguniform(\"lr\", 1e-4, 3e-3)\n",
    "    dropout_p  = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
    "    weight_dec = trial.suggest_loguniform(\"wd\", 1e-5, 1e-3)\n",
    "    unfreeze   = trial.suggest_int(\"unfreeze\", 50, 150, step=25)\n",
    "\n",
    "    # model\n",
    "    model = mobilenet_v2_ft(num_classes, unfreeze_from=unfreeze)\n",
    "    model.classifier[0] = nn.Dropout(dropout_p)\n",
    "    model.to(device)\n",
    "\n",
    "    opt  = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_dec)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val, stale = 0, 0\n",
    "    for epoch in range(1, 11):            # max 10 epochs each trial\n",
    "        # train one epoch\n",
    "        model.train()\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            opt.zero_grad(); out = model(X); loss = crit(out, y)\n",
    "            loss.backward(); opt.step()\n",
    "\n",
    "        # val acc\n",
    "        model.eval(); correct = total = 0\n",
    "        with torch.inference_mode():\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                correct += (model(X).argmax(1) == y).sum().item()\n",
    "                total   += y.size(0)\n",
    "        val_acc = correct / total\n",
    "        trial.report(val_acc, epoch)\n",
    "\n",
    "        if trial.should_prune():   # early‑prune bad trials\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        if val_acc > best_val:\n",
    "            best_val, stale = val_acc, 0\n",
    "        else:\n",
    "            stale += 1\n",
    "            if stale >= 3: break   # our own patience\n",
    "\n",
    "    return best_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the study\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=25, timeout=60*60)   # 1 hour budget\n",
    "print(\"Best trial:\", study.best_trial.params, \"→\", study.best_value)\n",
    "study.trials_dataframe().to_csv(\"optuna_mobilenet.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5374a1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
